{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_pattern = '/Users/qijia/Downloads/ztfvariable/field000202/ztf_000202_zg_c13_q2_dr21.parquet'\n",
    "df = pd.read_parquet(file_pattern)\n",
    "# print(df)\n",
    "# df.to_csv('/Users/qijia/Downloads/ztfvariable/dataframe.csv',index=False)\n",
    "hjd=df['hmjd']-50000\n",
    "print(hjd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download parquet\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup  \n",
    "base_url = 'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/field000202/'\n",
    "download_folder = '/Users/qijia/Downloads/ztfvariable/'  \n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href.endswith('.parquet'):\n",
    "        file_url = urljoin(base_url, href)\n",
    "        file_name = href.split('/')[-1]  \n",
    "        file_path = download_folder + file_name  \n",
    "        print(f'Downloading {file_url}...')\n",
    "        r = requests.get(file_url, stream=True)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f'{file_name} downloaded successfully.')\n",
    "print('All files downloaded.')\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup  \n",
    "\n",
    "base_url = 'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/field000202/'\n",
    "download_folder = '/Users/qijia/Downloads/ztfvariable/field000202/'  \n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href.endswith('.parquet'):\n",
    "        file_url = urljoin(base_url, href)\n",
    "        file_name = href.split('/')[-1]  \n",
    "        file_path = os.path.join(download_folder, file_name)  \n",
    "        print(f'Downloading {file_url}...')\n",
    "        r = requests.get(file_url, stream=True)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f'{file_name} downloaded successfully.')\n",
    "\n",
    "print('All files downloaded.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download field and parquet\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "base_url = 'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/'\n",
    "download_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href.startswith('field'):\n",
    "        field_url = urljoin(base_url, href)\n",
    "        # print(f'Processing {field_url}...')\n",
    "        field_number = href.strip('/')\n",
    "        field_folder = os.path.join(download_folder, field_number)\n",
    "        os.makedirs(field_folder, exist_ok=True)\n",
    "        field_response = requests.get(field_url)\n",
    "        field_soup = BeautifulSoup(field_response.content, 'html.parser')\n",
    "        field_links = field_soup.find_all('a')\n",
    "        for field_link in field_links:\n",
    "            field_href = field_link.get('href')\n",
    "            if field_href.endswith('.parquet'):\n",
    "                file_url = urljoin(field_url, field_href)\n",
    "                file_name = field_href.split('/')[-1]\n",
    "                file_path = os.path.join(field_folder, file_name)\n",
    "                # print(f'Downloading {file_url}...')\n",
    "                r = requests.get(file_url, stream=True)\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                # print(f'{file_name} downloaded successfully.')\n",
    "# print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download field and parquet, if pasue\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/'\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "links = soup.find_all('a')\n",
    "field_numbers = set()\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href and href.startswith('field'):\n",
    "        field_number = href.split('/')[0]\n",
    "        if field_number.startswith('field'):\n",
    "            field_number = field_number[5:]\n",
    "            field_numbers.add(field_number)\n",
    "field_numbers = sorted(field_numbers)\n",
    "base_download_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "\n",
    "for field_num in range(1, 1001):\n",
    "    str_field_num = f'{field_num:06d}'  \n",
    "    if str_field_num in field_numbers:\n",
    "        download_folder = os.path.join(base_download_folder, f'field{str_field_num}/')\n",
    "        if not os.path.exists(download_folder):\n",
    "            os.makedirs(download_folder, exist_ok=True)\n",
    "            field_url = f'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/field{str_field_num}/'\n",
    "            response = requests.get(field_url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            links = soup.find_all('a')\n",
    "            for link in links:\n",
    "                href = link.get('href')\n",
    "                if href.endswith('.parquet'):\n",
    "                    file_url = urljoin(field_url, href)\n",
    "                    file_name = href.split('/')[-1]  \n",
    "                    file_path = os.path.join(download_folder, file_name)  \n",
    "                    r = requests.get(file_url, stream=True)\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and process\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "\n",
    "\n",
    "def fourier1(t, a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, b6):\n",
    "    series = a0 + a1*cos(2*np.pi*t)+ b1*sin(2*np.pi*t) + a2*cos(4*np.pi*t) + b2*sin(4*np.pi*t) + a3*cos(6*np.pi*t) + b3*sin(6*np.pi*t) + a4*cos(8*np.pi*t) + b4*sin(8*np.pi*t) + a5*cos(10*np.pi*t) + b5*sin(10*np.pi*t) + a6*cos(12*np.pi*t) + b6*sin(12*np.pi*t)\n",
    "    return series\n",
    "\n",
    "\n",
    "base_url = 'https://irsa.ipac.caltech.edu/data/ZTF/lc/lc_dr21/0/'\n",
    "download_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href.startswith('field'):\n",
    "        field_url = urljoin(base_url, href)\n",
    "        print(f'Processing {field_url}...')\n",
    "        field_number = href.strip('/')\n",
    "        field_folder = os.path.join(download_folder, field_number)\n",
    "        os.makedirs(field_folder, exist_ok=True)\n",
    "        field_response = requests.get(field_url)\n",
    "        field_soup = BeautifulSoup(field_response.content, 'html.parser')\n",
    "        field_links = field_soup.find_all('a')\n",
    "        for field_link in field_links:\n",
    "            field_href = field_link.get('href')\n",
    "            if field_href.endswith('.parquet'):\n",
    "                file_url = urljoin(field_url, field_href)\n",
    "                file_name = field_href.split('/')[-1]\n",
    "                file_path = os.path.join(field_folder, file_name)\n",
    "                print(f'Downloading {file_url}...')\n",
    "                r = requests.get(file_url, stream=True)\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                print(f'{file_name} downloaded successfully.')\n",
    "print('All files downloaded.')\n",
    "\n",
    "\n",
    "root_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "# Walk through the root folder to find all 'field' subfolders\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    # Check if the directory is a field subfolder\n",
    "    if 'field' in os.path.basename(dirpath):\n",
    "        file_pattern = os.path.join(dirpath, '*.parquet')  # Corrected pattern to include all parquet files\n",
    "        file_paths = glob.glob(file_pattern)\n",
    "        save_data = pd.DataFrame(columns=['objectid', 'filterid', 'ra', 'dec', 'fre', 'psd', 'period','fap','amp'])\n",
    "        for file_path in file_paths:\n",
    "            df = pd.read_parquet(file_path)\n",
    "            for index, row in df.iterrows():\n",
    "                nsecond = row['nepochs']\n",
    "                if pd.isna(nsecond):\n",
    "                    continue\n",
    "                if nsecond > 60:\n",
    "                    objectid = row['objectid']\n",
    "                    filterid = row['filterid']\n",
    "                    fieldid = row['fieldid']\n",
    "                    ra = row['objra']\n",
    "                    dec = row['objdec']\n",
    "                    mag = row['mag']\n",
    "                    hjd = row['hmjd']\n",
    "                    magerr = row['magerr']\n",
    "                    newdf = pd.DataFrame({'hjd': hjd, 'mag': mag, 'magerr': magerr})\n",
    "                    sort_idx = np.argsort(newdf.hjd)\n",
    "                    newdf = newdf.iloc[sort_idx]  \n",
    "                    sort_hjd = newdf.hjd\n",
    "                    sort_mag = newdf.mag\n",
    "                    sort_mge = newdf.magerr\n",
    "                    aa, tb = np.unique(sort_hjd, return_inverse=True)\n",
    "                    khjd2 = sort_hjd[np.isin(np.arange(len(sort_hjd)), tb)]\n",
    "                    kmag2 = sort_mag[np.isin(np.arange(len(sort_mag)), tb)]\n",
    "                    kmge2 = sort_mge[np.isin(np.arange(len(sort_mge)), tb)]\n",
    "                    df2=pd.DataFrame({'hjd':khjd2,'mag':kmag2,'magerr':kmge2})\n",
    "                    df2['hjd_diff']=df2['hjd'].diff().fillna(df2['hjd'])\n",
    "                    to_remove = df2['hjd_diff']<=0.001\n",
    "                    df_filtered=df2[~to_remove]\n",
    "                    df_filtered = df_filtered.dropna(subset=['hjd'])\n",
    "                    each_star=df_filtered.to_records(index=False)\n",
    "                    # filtered_meanmag=np.mean(each_star.mag)\n",
    "                    # filtered_meanmagerr=np.mean(each_star.magerr)\n",
    "                    f, p = LombScargle(each_star['hjd'], each_star['mag']).autopower(samples_per_peak=10, minimum_frequency=1, maximum_frequency=10)\n",
    "                    max_p = p.argmax()\n",
    "                    f_final = f[max_p]\n",
    "                    p_max = p[max_p]\n",
    "                    period = 1 / f_final\n",
    "                    fap= np.log10(LombScargle(each_star.hjd, each_star.mag).false_alarm_probability(power=p_max))\n",
    "                    phase = ((each_star.hjd - each_star.hjd[0])/period)%1 \n",
    "                    t, y = variables('t, y')\n",
    "                    model_dict = {y: fourier1(t, a0=Parameter('a0'), a1=Parameter('a1'), a2=Parameter('a2'), a3=Parameter('a3'), a4=Parameter('a4'),a5=Parameter('a5'),a6=Parameter('a6'),b1=Parameter('b1'), b2=Parameter('b2'), b3=Parameter('b3'), b4=Parameter('b4'),b5=Parameter('b5'),b6=Parameter('b6'))}\n",
    "                    fit = Fit(model_dict, t=np.array(phase), y=np.array(each_star.mag))\n",
    "                    fit_result = fit.execute()\n",
    "                    params = fit_result.params\n",
    "                    t_fit = np.linspace(np.min(phase), 2*np.max(phase), 2000)\n",
    "                    model_values = fit_result.model(t=t_fit, **params)\n",
    "                    model_values = np.squeeze(model_values)  \n",
    "                    # predict_max = np.max(model_values)\n",
    "                    # predict_min = np.min(model_values)\n",
    "                    amplitude = np.max(model_values) - np.min(model_values)\n",
    "                    save_data = pd.concat([save_data, pd.DataFrame({'objectid': objectid, 'filterid': filterid, 'ra': ra, 'dec': dec, 'fre': f_final, 'psd': p_max, 'period': period,'fap':fap,'amp':amplitude}, index=[0])], ignore_index=True)\n",
    "        if len(save_data) > 0:\n",
    "            subfolder_name = os.path.basename(dirpath)\n",
    "            output_path = os.path.join(dirpath, f'{subfolder_name}_processed_data.csv')\n",
    "            save_data.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work in the field\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "import tqdm\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "def fourier1(t, a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, b6):\n",
    "    series = a0 + a1*cos(2*np.pi*t)+ b1*sin(2*np.pi*t) + a2*cos(4*np.pi*t) + b2*sin(4*np.pi*t) + a3*cos(6*np.pi*t) + b3*sin(6*np.pi*t) + a4*cos(8*np.pi*t) + b4*sin(8*np.pi*t) + a5*cos(10*np.pi*t) + b5*sin(10*np.pi*t) + a6*cos(12*np.pi*t) + b6*sin(12*np.pi*t)\n",
    "    return series\n",
    "parquet_folder = '/Users/qijia/Downloads/ztfvariable/field000228'\n",
    "file_pattern = os.path.join(parquet_folder, '*.parquet')\n",
    "file_paths = glob.glob(file_pattern)\n",
    "save_data = pd.DataFrame(columns=['objectid', 'filterid', 'ra', 'dec', 'mag','fre', 'psd', 'period','fap','amp','R2'])\n",
    "for file_path in file_paths:\n",
    "# for file_path in tqdm(file_paths, desc='Processing Parquet Files'):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    for index, row in df.iterrows():\n",
    "        nsecond = row['nepochs']\n",
    "        if pd.isna(nsecond):\n",
    "            continue\n",
    "        if nsecond > 100:\n",
    "            filterid = row['filterid']\n",
    "            if filterid==3:\n",
    "                pass\n",
    "            else:\n",
    "                objectid = row['objectid']\n",
    "                ra = row['objra']\n",
    "                dec = row['objdec']\n",
    "                mag = row['mag']\n",
    "                hjd = row['hmjd']\n",
    "                magerr = row['magerr']\n",
    "                newdf = pd.DataFrame({'hjd': hjd, 'mag': mag, 'magerr': magerr})\n",
    "\n",
    "                mu=np.median(newdf.mag)\n",
    "                newdf=newdf[np.abs(newdf.mag-mu)<2]\n",
    "                std=np.std(newdf.mag)\n",
    "                mu2=np.median(newdf.mag)\n",
    "                newdf=newdf[np.abs(newdf.mag-mu2)<3*std]\n",
    "\n",
    "                sort_idx = np.argsort(newdf.hjd)\n",
    "                newdf = newdf.iloc[sort_idx]  \n",
    "                sort_hjd = newdf.hjd\n",
    "                sort_mag = newdf.mag\n",
    "                sort_mge = newdf.magerr\n",
    "                aa, tb = np.unique(sort_hjd, return_inverse=True)\n",
    "                khjd2 = sort_hjd[np.isin(np.arange(len(sort_hjd)), tb)]\n",
    "                kmag2 = sort_mag[np.isin(np.arange(len(sort_mag)), tb)]\n",
    "                kmge2 = sort_mge[np.isin(np.arange(len(sort_mge)), tb)]\n",
    "                df2=pd.DataFrame({'hjd':khjd2,'mag':kmag2,'magerr':kmge2})\n",
    "                mean_mag=np.mean(df2.mag)\n",
    "                df2['hjd_diff']=df2['hjd'].diff().fillna(df2['hjd'])\n",
    "                to_remove = df2['hjd_diff']<=0.001\n",
    "                df_filtered=df2[~to_remove]\n",
    "                df_filtered = df_filtered.dropna(subset=['hjd'])\n",
    "                each_star=df_filtered.to_records(index=False)\n",
    "                # filtered_meanmag=np.mean(each_star.mag)\n",
    "                # filtered_meanmagerr=np.mean(each_star.magerr)\n",
    "                f, p = LombScargle(each_star['hjd'], each_star['mag']).autopower(samples_per_peak=10, minimum_frequency=1, maximum_frequency=10)\n",
    "                max_p = p.argmax()\n",
    "                f_final = f[max_p]\n",
    "                p_max = p[max_p]\n",
    "                period = 1 / f_final\n",
    "                phase = ((each_star.hjd - each_star.hjd[0])/period)%1 \n",
    "                t, y = variables('t, y')\n",
    "                model_dict = {y: fourier1(t, a0=Parameter('a0'), a1=Parameter('a1'), a2=Parameter('a2'), a3=Parameter('a3'), a4=Parameter('a4'),a5=Parameter('a5'),a6=Parameter('a6'),b1=Parameter('b1'), b2=Parameter('b2'), b3=Parameter('b3'), b4=Parameter('b4'),b5=Parameter('b5'),b6=Parameter('b6'))}\n",
    "                fit = Fit(model_dict, t=np.array(phase), y=np.array(each_star.mag))\n",
    "                fit_result = fit.execute()\n",
    "                params = fit_result.params\n",
    "                t_fit = np.linspace(np.min(phase), 2*np.max(phase), 2000)\n",
    "                model_values = fit_result.model(t=t_fit, **params)\n",
    "                model_at_data = fit_result.model(t=np.array(phase), **params)\n",
    "                mean_mag = np.mean(each_star.mag)\n",
    "                SS_total = np.sum((each_star.mag - mean_mag) ** 2)\n",
    "                SS_residual = np.sum((each_star.mag - model_at_data) ** 2)\n",
    "                R2 = 1 - (SS_residual / SS_total)\n",
    "                amplitude = np.max(model_values) - np.min(model_values)\n",
    "                if amplitude<0.01:\n",
    "                    pass\n",
    "                else:\n",
    "                    fap= np.log10(LombScargle(each_star.hjd, each_star.mag).false_alarm_probability(power=p_max))\n",
    "                    if fap>0.001:\n",
    "                        pass\n",
    "                    else:\n",
    "                        save_data = pd.concat([save_data, pd.DataFrame({'objectid': objectid, 'filterid': filterid, 'ra': ra, 'dec': dec, 'mag':mean_mag,'fre': f_final, 'psd': p_max, 'period': period,'fap':fap,'amp':amplitude,'R2':R2}, index=[0])], ignore_index=True)\n",
    "if len(save_data) > 0:\n",
    "    subfolder_name = os.path.basename(parquet_folder)\n",
    "    output_path = os.path.join(parquet_folder, f'{subfolder_name}_processed_data.csv')\n",
    "    save_data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work in the field , check csv exist\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def fourier1(t, a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, b6):\n",
    "    series = a0 + a1*cos(2*np.pi*t)+ b1*sin(2*np.pi*t) + a2*cos(4*np.pi*t) + b2*sin(4*np.pi*t) + a3*cos(6*np.pi*t) + b3*sin(6*np.pi*t) + a4*cos(8*np.pi*t) + b4*sin(8*np.pi*t) + a5*cos(10*np.pi*t) + b5*sin(10*np.pi*t) + a6*cos(12*np.pi*t) + b6*sin(12*np.pi*t)\n",
    "    return series\n",
    "\n",
    "root_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "\n",
    "for field_num in range(1001):\n",
    "    str_field_num = f'{field_num:06d}'  \n",
    "    download_folder = os.path.join(root_folder, f'field{str_field_num}/{str_field_num}_processed_data.csv')\n",
    "    if not os.path.exists(download_folder):\n",
    "        parquet_folder = os.path.join(root_folder, f'field{str_field_num}/')\n",
    "        file_pattern = os.path.join(parquet_folder, '*.parquet')\n",
    "        file_paths = glob.glob(file_pattern)\n",
    "        save_data = pd.DataFrame(columns=['objectid', 'filterid', 'ra', 'dec', 'fre', 'psd', 'period','fap','amp','R2'])\n",
    "        for file_path in file_paths:\n",
    "            df = pd.read_parquet(file_path)\n",
    "            for index, row in df.iterrows():\n",
    "                nsecond = row['nepochs']\n",
    "                if pd.isna(nsecond):\n",
    "                    continue\n",
    "                if nsecond > 60:\n",
    "                    filterid = row['filterid']\n",
    "                    if filterid==3:\n",
    "                        pass\n",
    "                    else:\n",
    "                        objectid = row['objectid']\n",
    "                        ra = row['objra']\n",
    "                        dec = row['objdec']\n",
    "                        meanmag = np.mean(row['mag'])\n",
    "                        mag = row['mag']\n",
    "                        hjd = row['hmjd']\n",
    "                        magerr = row['magerr']\n",
    "                        newdf = pd.DataFrame({'hjd': hjd, 'mag': mag, 'magerr': magerr})\n",
    "                        sort_idx = np.argsort(newdf.hjd)\n",
    "                        newdf = newdf.iloc[sort_idx]  \n",
    "                        sort_hjd = newdf.hjd\n",
    "                        sort_mag = newdf.mag\n",
    "                        sort_mge = newdf.magerr\n",
    "                        aa, tb = np.unique(sort_hjd, return_inverse=True)\n",
    "                        khjd2 = sort_hjd[np.isin(np.arange(len(sort_hjd)), tb)]\n",
    "                        kmag2 = sort_mag[np.isin(np.arange(len(sort_mag)), tb)]\n",
    "                        kmge2 = sort_mge[np.isin(np.arange(len(sort_mge)), tb)]\n",
    "                        df2=pd.DataFrame({'hjd':khjd2,'mag':kmag2,'magerr':kmge2})\n",
    "                        df2['hjd_diff']=df2['hjd'].diff().fillna(df2['hjd'])\n",
    "                        to_remove = df2['hjd_diff']<=0.001\n",
    "                        df_filtered=df2[~to_remove]\n",
    "                        df_filtered = df_filtered.dropna(subset=['hjd'])\n",
    "                        each_star=df_filtered.to_records(index=False)\n",
    "                        filtered_meanmag=np.mean(each_star.mag)\n",
    "                        filtered_meanmagerr=np.mean(each_star.magerr)\n",
    "                        f, p = LombScargle(each_star['hjd'], each_star['mag']).autopower(samples_per_peak=10, minimum_frequency=1, maximum_frequency=10)\n",
    "                        max_p = p.argmax()\n",
    "                        f_final = f[max_p]\n",
    "                        p_max = p[max_p]\n",
    "                        period = 1 / f_final\n",
    "                        fap= np.log10(LombScargle(each_star.hjd, each_star.mag).false_alarm_probability(power=p_max))\n",
    "                        phase = ((each_star.hjd - each_star.hjd[0])/period)%1 \n",
    "                        t, y = variables('t, y')\n",
    "                        model_dict = {y: fourier1(t, a0=Parameter('a0'), a1=Parameter('a1'), a2=Parameter('a2'), a3=Parameter('a3'), a4=Parameter('a4'),a5=Parameter('a5'),a6=Parameter('a6'),b1=Parameter('b1'), b2=Parameter('b2'), b3=Parameter('b3'), b4=Parameter('b4'),b5=Parameter('b5'),b6=Parameter('b6'))}\n",
    "                        fit = Fit(model_dict, t=np.array(phase), y=np.array(each_star.mag))\n",
    "                        fit_result = fit.execute()\n",
    "                        params = fit_result.params\n",
    "                        t_fit = np.linspace(np.min(phase), 2*np.max(phase), 2000)\n",
    "                        model_values = fit_result.model(t=t_fit, **params)\n",
    "                        model_at_data = fit_result.model(t=np.array(phase), **params)\n",
    "                        mean_mag = np.mean(each_star.mag)\n",
    "                        SS_total = np.sum((each_star.mag - mean_mag) ** 2)\n",
    "                        SS_residual = np.sum((each_star.mag - model_at_data) ** 2)\n",
    "                        R2 = 1 - (SS_residual / SS_total)\n",
    "                        amplitude = np.max(model_values) - np.min(model_values)\n",
    "                        save_data = pd.concat([save_data, pd.DataFrame({'objectid': objectid, 'filterid': filterid, 'ra': ra, 'dec': dec, 'fre': f_final, 'psd': p_max, 'period': period,'fap':fap,'amp':amplitude,'R2':R2}, index=[0])], ignore_index=True)\n",
    "        if len(save_data) > 0:\n",
    "            output_path = os.path.join(parquet_folder, f'field{str_field_num}_processed_data.csv')\n",
    "            save_data.to_csv(output_path, index=False) \n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imag vision\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def fourier1(t, a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, b6):\n",
    "    series = a0 + a1*cos(2*np.pi*t)+ b1*sin(2*np.pi*t) + a2*cos(4*np.pi*t) + b2*sin(4*np.pi*t) + a3*cos(6*np.pi*t) + b3*sin(6*np.pi*t) + a4*cos(8*np.pi*t) + b4*sin(8*np.pi*t) + a5*cos(10*np.pi*t) + b5*sin(10*np.pi*t) + a6*cos(12*np.pi*t) + b6*sin(12*np.pi*t)\n",
    "    return series\n",
    "\n",
    "\n",
    "def psd_and_lc(source,ra, dec,f, p, period, f_final, p_max, phase, each_star, t_fit, model_values,lable_str,figurepath):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 3), dpi=300)\n",
    "    axs[0].scatter(f_final, p_max, marker='o', color='r', s=20, alpha=1)\n",
    "    axs[0].plot(f, p, color='b', linestyle='-', linewidth=1.0)\n",
    "    axs[0].text(0.9, 0.95, f\"ZTF {source}\", transform=axs[0].transAxes, fontsize=8, fontweight='normal', va='top', ha='right', color='k')\n",
    "    axs[0].set_xlabel('Frequency', fontsize=6, color='k')\n",
    "    axs[0].set_ylabel('PSD', fontsize=6, color='k')\n",
    "    axs[0].xaxis.set_minor_locator(MultipleLocator(5))  \n",
    "    axs[0].tick_params(axis='both', which='major', direction='in', length=4, width=0.8, colors='k',grid_color='r', grid_alpha=0.5)\n",
    "    axs[0].tick_params(axis='both', which='minor', direction='in', length=2, width=0.8, colors='k',grid_color='r', grid_alpha=0.5)\n",
    "    axs[0].tick_params(axis='both', labelsize=7)\n",
    "    axs[0].set_xlim(0,40) \n",
    "    axs[0].set_ylim(0, None) \n",
    "    \n",
    "    axs[1].scatter(phase, each_star.mag, color='r',s=1,alpha=0.7)\n",
    "    axs[1].scatter([p+1 for p in phase], each_star.mag, color='r',s=1,alpha=0.7) \n",
    "    axs[1].plot(t_fit, model_values, 'g-', alpha=1, label='Fit', linewidth=2, zorder=2) \n",
    "    axs[1].text(0.9, 0.95, f\"Period = {period:.8f} [day]\", transform=axs[1].transAxes, fontsize=8, fontweight='normal', va='top', ha='right', color='k')\n",
    "    axs[1].set_xlabel('Pulsation phase', fontsize=6, color='k')\n",
    "    axs[1].set_ylabel(f'${lable_str}$ (mag)', fontsize=6, color='k')\n",
    "    axs[1].xaxis.set_minor_locator(MultipleLocator(0.25))  \n",
    "    axs[1].tick_params(axis='both', which='major', direction='in', length=4, width=0.8, colors='k',grid_color='r', grid_alpha=0.5)\n",
    "    axs[1].tick_params(axis='both', which='minor', direction='in', length=2, width=0.8, colors='k',grid_color='r', grid_alpha=0.5)\n",
    "    axs[1].tick_params(axis='both', labelsize=7)\n",
    "    axs[1].invert_yaxis()\n",
    "\n",
    "    fileName = f\"ra={ra},dec={dec}.png\"\n",
    "    fullPath = os.path.join(figurepath, fileName)\n",
    "    plt.savefig(fullPath, format='png', dpi=300)\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "root_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "figurepath = '/Users/qijia/Downloads/ztfvariable/figure/'\n",
    "\n",
    "# Walk through the root folder to find all 'field' subfolders\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    # Check if the directory is a field subfolder\n",
    "    if 'field' in os.path.basename(dirpath):\n",
    "        file_pattern = os.path.join(dirpath, '*.parquet')  # Corrected pattern to include all parquet files\n",
    "        file_paths = glob.glob(file_pattern)\n",
    "        for file_path in file_paths:\n",
    "            df = pd.read_parquet(file_path)\n",
    "            for index, row in df.iterrows():\n",
    "                nsecond = row['nepochs']\n",
    "                if pd.isna(nsecond):\n",
    "                    continue\n",
    "                if nsecond > 300:\n",
    "                    filterid = row['filterid']\n",
    "                    if filterid==3:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if filterid==1:\n",
    "                            lable_str='g'\n",
    "                        if filterid==2:\n",
    "                            lable_str='r'\n",
    "                        objectid = row['objectid']\n",
    "                        ra = row['objra']\n",
    "                        dec = row['objdec']\n",
    "                        meanmag = np.mean(row['mag'])\n",
    "                        mag = row['mag']\n",
    "                        hjd = row['hmjd']\n",
    "                        magerr = row['magerr']\n",
    "                        newdf = pd.DataFrame({'hjd': hjd, 'mag': mag, 'magerr': magerr})\n",
    "                        sort_idx = np.argsort(newdf.hjd)\n",
    "                        newdf = newdf.iloc[sort_idx]  \n",
    "                        sort_hjd = newdf.hjd\n",
    "                        sort_mag = newdf.mag\n",
    "                        sort_mge = newdf.magerr\n",
    "                        aa, tb = np.unique(sort_hjd, return_inverse=True)\n",
    "                        khjd2 = sort_hjd[np.isin(np.arange(len(sort_hjd)), tb)]\n",
    "                        kmag2 = sort_mag[np.isin(np.arange(len(sort_mag)), tb)]\n",
    "                        kmge2 = sort_mge[np.isin(np.arange(len(sort_mge)), tb)]\n",
    "                        df2=pd.DataFrame({'hjd':khjd2,'mag':kmag2,'magerr':kmge2})\n",
    "                        df2['hjd_diff']=df2['hjd'].diff().fillna(df2['hjd'])\n",
    "                        to_remove = df2['hjd_diff']<=0.001\n",
    "                        df_filtered=df2[~to_remove]\n",
    "                        df_filtered = df_filtered.dropna(subset=['hjd'])\n",
    "                        each_star=df_filtered.to_records(index=False)\n",
    "                        # filtered_meanmag=np.mean(each_star.mag)\n",
    "                        # filtered_meanmagerr=np.mean(each_star.magerr)\n",
    "                        f, p = LombScargle(each_star['hjd'], each_star['mag']).autopower(samples_per_peak=10, minimum_frequency=1, maximum_frequency=10)\n",
    "                        max_p = p.argmax()\n",
    "                        f_final = f[max_p]\n",
    "                        p_max = p[max_p]\n",
    "                        period = 1 / f_final\n",
    "                        phase = ((each_star.hjd - each_star.hjd[0])/period)%1 \n",
    "                        t, y = variables('t, y')\n",
    "                        model_dict = {y: fourier1(t, a0=Parameter('a0'), a1=Parameter('a1'), a2=Parameter('a2'), a3=Parameter('a3'), a4=Parameter('a4'),a5=Parameter('a5'),a6=Parameter('a6'),b1=Parameter('b1'), b2=Parameter('b2'), b3=Parameter('b3'), b4=Parameter('b4'),b5=Parameter('b5'),b6=Parameter('b6'))}\n",
    "                        fit = Fit(model_dict, t=np.array(phase), y=np.array(each_star.mag))\n",
    "                        fit_result = fit.execute()\n",
    "                        params = fit_result.params\n",
    "                        t_fit = np.linspace(np.min(phase), 2*np.max(phase), 2000)\n",
    "                        model_values = fit_result.model(t=t_fit, **params)\n",
    "                        model_values = np.squeeze(model_values)  \n",
    "                        psd_and_lc(objectid,ra, dec,f, p, period, f_final, p_max, phase, each_star, t_fit, model_values,lable_str,figurepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data vision\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "from symfit import parameters, variables, sin, cos, Fit, Variable, Parameter\n",
    "\n",
    "def fourier1(t, a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, b6):\n",
    "    series = a0 + a1*cos(2*np.pi*t)+ b1*sin(2*np.pi*t) + a2*cos(4*np.pi*t) + b2*sin(4*np.pi*t) + a3*cos(6*np.pi*t) + b3*sin(6*np.pi*t) + a4*cos(8*np.pi*t) + b4*sin(8*np.pi*t) + a5*cos(10*np.pi*t) + b5*sin(10*np.pi*t) + a6*cos(12*np.pi*t) + b6*sin(12*np.pi*t)\n",
    "    return series\n",
    "\n",
    "root_folder = '/Users/qijia/Downloads/ztfvariable/'\n",
    "# Walk through the root folder to find all 'field' subfolders\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    # Check if the directory is a field subfolder\n",
    "    if 'field' in os.path.basename(dirpath):\n",
    "        file_pattern = os.path.join(dirpath, '*.parquet')  # Corrected pattern to include all parquet files\n",
    "        file_paths = glob.glob(file_pattern)\n",
    "        save_data = pd.DataFrame(columns=['objectid', 'filterid', 'ra', 'dec', 'fre', 'psd', 'period','fap','amp','R2'])\n",
    "        for file_path in file_paths:\n",
    "            df = pd.read_parquet(file_path)\n",
    "            for index, row in df.iterrows():\n",
    "                nsecond = row['nepochs']\n",
    "                if pd.isna(nsecond):\n",
    "                    continue\n",
    "                if nsecond > 60:\n",
    "                    filterid = row['filterid']\n",
    "                    if filterid==3:\n",
    "                        pass\n",
    "                    else:\n",
    "                        objectid = row['objectid']\n",
    "                        ra = row['objra']\n",
    "                        dec = row['objdec']\n",
    "                        mag = row['mag']\n",
    "                        hjd = row['hmjd']\n",
    "                        magerr = row['magerr']\n",
    "                        newdf = pd.DataFrame({'hjd': hjd, 'mag': mag, 'magerr': magerr})\n",
    "\n",
    "                        mu=np.median(newdf.mag)\n",
    "                        newdf=newdf[np.abs(newdf.mag-mu)<2]\n",
    "                        std=np.std(newdf.mag)\n",
    "                        mu2=np.median(newdf.mag)\n",
    "                        newdf=newdf[np.abs(newdf.mag-mu2)<3*std]\n",
    "\n",
    "                        sort_idx = np.argsort(newdf.hjd)\n",
    "                        newdf = newdf.iloc[sort_idx]  \n",
    "                        sort_hjd = newdf.hjd\n",
    "                        sort_mag = newdf.mag\n",
    "                        sort_mge = newdf.magerr\n",
    "                        aa, tb = np.unique(sort_hjd, return_inverse=True)\n",
    "                        khjd2 = sort_hjd[np.isin(np.arange(len(sort_hjd)), tb)]\n",
    "                        kmag2 = sort_mag[np.isin(np.arange(len(sort_mag)), tb)]\n",
    "                        kmge2 = sort_mge[np.isin(np.arange(len(sort_mge)), tb)]\n",
    "                        df2=pd.DataFrame({'hjd':khjd2,'mag':kmag2,'magerr':kmge2})\n",
    "                        mean_mag=np.mean(df2.mag)\n",
    "                        df2['hjd_diff']=df2['hjd'].diff().fillna(df2['hjd'])\n",
    "                        to_remove = df2['hjd_diff']<=0.001\n",
    "                        df_filtered=df2[~to_remove]\n",
    "                        df_filtered = df_filtered.dropna(subset=['hjd'])\n",
    "                        each_star=df_filtered.to_records(index=False)\n",
    "                        # filtered_meanmag=np.mean(each_star.mag)\n",
    "                        # filtered_meanmagerr=np.mean(each_star.magerr)\n",
    "                        f, p = LombScargle(each_star['hjd'], each_star['mag']).autopower(samples_per_peak=10, minimum_frequency=1, maximum_frequency=10)\n",
    "                        max_p = p.argmax()\n",
    "                        f_final = f[max_p]\n",
    "                        p_max = p[max_p]\n",
    "                        period = 1 / f_final\n",
    "                        phase = ((each_star.hjd - each_star.hjd[0])/period)%1 \n",
    "                        t, y = variables('t, y')\n",
    "                        model_dict = {y: fourier1(t, a0=Parameter('a0'), a1=Parameter('a1'), a2=Parameter('a2'), a3=Parameter('a3'), a4=Parameter('a4'),a5=Parameter('a5'),a6=Parameter('a6'),b1=Parameter('b1'), b2=Parameter('b2'), b3=Parameter('b3'), b4=Parameter('b4'),b5=Parameter('b5'),b6=Parameter('b6'))}\n",
    "                        fit = Fit(model_dict, t=np.array(phase), y=np.array(each_star.mag))\n",
    "                        fit_result = fit.execute()\n",
    "                        params = fit_result.params\n",
    "                        t_fit = np.linspace(np.min(phase), 2*np.max(phase), 2000)\n",
    "                        model_values = fit_result.model(t=t_fit, **params)\n",
    "                        model_at_data = fit_result.model(t=np.array(phase), **params)\n",
    "                        mean_mag = np.mean(each_star.mag)\n",
    "                        SS_total = np.sum((each_star.mag - mean_mag) ** 2)\n",
    "                        SS_residual = np.sum((each_star.mag - model_at_data) ** 2)\n",
    "                        R2 = 1 - (SS_residual / SS_total)\n",
    "                        amplitude = np.max(model_values) - np.min(model_values)\n",
    "                        if amplitude<0.01:\n",
    "                            pass\n",
    "                        else:\n",
    "                            fap= np.log10(LombScargle(each_star.hjd, each_star.mag).false_alarm_probability(power=p_max))\n",
    "                            if fap>0.001:\n",
    "                                pass\n",
    "                            else:\n",
    "                                save_data = pd.concat([save_data, pd.DataFrame({'objectid': objectid, 'filterid': filterid, 'ra': ra, 'dec': dec, 'mag':meanmag,'fre': f_final, 'psd': p_max, 'period': period,'fap':fap,'amp':amplitude,'R2':R2}, index=[0])], ignore_index=True)\n",
    "        if len(save_data) > 0:\n",
    "            subfolder_name = os.path.basename(dirpath)\n",
    "            output_path = os.path.join(dirpath, f'{subfolder_name}_processed_data.csv')\n",
    "            save_data.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
